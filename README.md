# 小红书爬虫

使用 DrissionPage 初步完成小红书帖子的爬取逻辑

建议使用miniconda安装虚拟python环境, 使用以下命令安装依赖

```py
pip install -r requirements.txt
```

现在爬是可以爬了，但是在发现在依次点击时会自动往下翻页，又因为每次都要重新获取点击元素的引用，返回的元素顺序可能不同

- [x] 因此需要一个验证机制：

前一次获取的时候将元素相关的信息保存下来，然后去匹配已保存的点击元素的新的引用, 对于新的点击元素，加入这个数组

当前已经实现自动爬取和下滑, 但是有的页面在爬取时会出现差错, 此时需要手动关闭再次打开详情页才能正常工作:

```bash
获取到详情数据包
处理元素时出现错误: local variable 'tags' referenced before assignment
将会用来匹配的index: 106
```

程序健壮性和容错能力有待提高