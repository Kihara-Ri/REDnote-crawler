# 小红书爬虫

使用 DrissionPage 初步完成小红书帖子的爬取逻辑

建议使用miniconda安装虚拟python环境, 使用以下命令安装依赖

```py
pip install -r requirements.txt
```

现在爬是可以爬了，但是在发现在依次点击时会自动往下翻页，又因为每次都要重新获取点击元素的引用，返回的元素顺序可能不同

因此需要一个验证机制：
- 前一次获取的时候将元素相关的信息保存下来，然后去匹配已保存的点击元素的新的引用
- 对于新的点击元素，加入这个数组